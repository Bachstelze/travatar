<html>
<head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <title>Travatar - Parsing for Travatar</title>
    <link href="main.css" rel="stylesheet" type="text/css">
</head>
<body>

<div id="all">
<div id="sidebar">

<img src="img/travatar-logo.png" width=198 height=94>

<p>Travatar Main</p>
<ul>
<li><a href="index.html">Home</a></li>
<li><a href="todo.html">Future Plans</a></li>
</ul>

<p>Training</p>
<ul>
<li><a href="training-guide.html">Training Guide</a></li>
<li><a href="preprocessing.html">Preprocessing</a></li>
<li><a href="parsing.html">Parsing</a></li>
<li><a href="training-options.html">Training Options</a></li>
<li><a href="tree-converter.html">Tree Conversion</a></li>
<li><a href="model-format.html">Model Format</a></li>
</ul>

<p>Translating</p>

<ul>
<li><a href="decoding-options.html">Decoding Options</a></li>
<li><a href="evaluation.html">Evaluation</a></li>
</ul>

<p>Other</p>

<ul>
<li><a href="links.html">Links/ Acknowledgements</a></li>
</ul>


</div>
<div id="main">

<h1>Parsing for Travatar</h1>

<p>
Travatar is a tree-to-string translation system, which means that it requires source language parse trees to perform translation.
Within this framework, better parse trees will often directly improve your translation accuracy, so it is worth investing a little bit of time to created good trees.
It can also use packed forests, which encode a large number of trees at decoding time, so using a parser that has the ability to output packed forests is also effective.
This page describes how to perform the parsing step on your own, which is useful if you want to adjust various parameters of the parser, but there is also a <a href="preprocessing.html">preprocessing script</a> that makes it a bit easier to get going quickly.
</p>

<ul>
<li><a href="#english">Parsing English</a></li>
<li><a href="#japanese">Parsing Japanese</a></li>
<li><a href="#chinese">Parsing Chinese</a></li>
<li><a href="#defr">Parsing German/French</a></li>
</ul>

<a name="english">
<h2>Parsing English</h2>

<p>
For parsing English, you can use any phrase structure parser of your choosing.
In particular, we recommend the <a href="http://github.com/odashi/Ckylark">Ckylark</a> parser for trees, or <a href="http://github.com/neubig/egret">Egret</a> parser for forests.
Note that parsing has a large effect on translation results (<a href="http://phontron.com/paper/neubig14acl.pdf">Neubig&Duh ACL2014</a>), so it might be worth trying other newer parsers.
</p>

<h3>Tokenization</h3>

<p>
Before parsing, you will have to tokenize your input.
Travatar includes a tokenizer that does a reasonable job at tokenizing English, so you can use it on an input text <tt>input.txt</tt> as follows:
</p>

<pre>
cat input.txt | travatar/src/bin/tokenizer &gt; tokenized.txt
</pre>

<h3>Ckylark</h3>

<p>
As mentioned in the <a href="training-guide.html">training guide</a>, the <a href="http://github.com/odashi/Ckylark">Ckylark</a> parser is a good parser for generating trees, as it is accurate and will rarely fail at parsing.
To install the parser, if you haven't already, clone it from github, and follow the installation directions.
Then, if we want to parse English we will have to unzip the English parsing model (named WSJ, as it was trained on the Wall Street Journal section of the Penn Treebank).
</p>

<pre>
gunzip Ckylark/model/wsj.*.gz
</pre>

<p>
Next, we can use this model to parse English sentences using the following command.
</p>

<pre>
cat tokenized.txt | Ckylark/src/ckylark --model Ckylark/model/wsj &gt; ckylark-parsed.txt
</pre>

<h3>Egret</h3>

<p>
<a href="http://code.google.com/p/egret-parser/">Egret</a> is a parser that is able to output packed forests that can be used in translation.
</p>

<h4>Installation</h4>

<p>
Download Egret from the <a href="http://github.com/neubig/egret">github page</a> and unzip it.
You can then run the following command in the top directory to compile:
</p>
<pre>
bash make-linux.sh
</pre>

<h4>Parsing 1-best Trees</h4>

<p>
For Travatar training (currently) only 1-best trees are supported for rule learning, so we will first describe how to create 1-best trees.
Given the tokenized file <tt>tokenized.txt</tt>, we then run Egret as follows, where <tt>$EGRET_DIR</tt> is the directory to which you downloaded Egret.
</p>

<pre>
$EGRET_DIR/egret -lapcfg -i=tokenized.txt -data=$EGRET_DIR/eng_grammar &gt; egret-parsed.txt
</pre>

<p>
Unfortunately, for some sentences, Egret's parsing fails and generates an empty tree "(())", maybe one in every 10000 or so sentences.
This means that we will not be able to extract rules from, or translate any failed sentences.
If we already have parse trees from the Ckylark parser, we can use the script <tt>replace-failed-parse.pl</tt> included with Travatar to replace only failed parses.
</p>

<pre>
$TRAVATAR_DIR/script/tree/replace-failed-parse.pl ckylark-parsed.txt egret-parsed.txt &gt; egret-parsefixed.txt
</pre>

<p>
If parsing is taking a lot of time, you can parse in parallel by running Egret on multiple processors and specifying <tt>-range</tt> to indicate which sentences you want to parse in that particular instance.
For example, if you have 1000 sentences to parse, you could run the following
</p>

<pre>
$EGRET_DIR/egret -range=1-500 -lapcfg -i=tokenized.txt -data=$EGRET_DIR/eng_grammar &gt; egret-parsed-1.txt &amp;
$EGRET_DIR/egret -range=501-1000 -lapcfg -i=tokenized.txt -data=$EGRET_DIR/eng_grammar &gt; egret-parsed-2.txt &amp;
</pre>

<p>
and then combine the two files together when both processes finish running.
</p>

<h4>Parsing Forests</h4>

<p>
Creating forests with Egret just requires a few extra options.
An example of the command can be found below:
</p>

<pre>
$EGRET_DIR/egret -lapcfg -i=tokenized.txt -data=$EGRET_DIR/eng_grammar -nbest4threshold=100 -printForest &gt; egret-forest.txt
</pre>

<p>
Here <tt>nbest4threshold=100</tt> indicates that we will only keep nodes or edges that appear in the 100 best parse trees.
This is generally a good setting, but larger forests can sometimes improve accuracy (<a href="http://phontron.com/paper/neubig14acl.pdf">Neubig&Duh ACL2014</a>).
</p>

<p>
Again, as some parses may fail, you can replace them with parses from Ckylark.
In order to do so, we first convert the Ckylark trees to forests with the <tt>tree-converter</tt> tool provided with Travatar, and then use the <tt>replace-failed-parse.pl</tt> script as we did before.
</p>

<pre>
$TRAVATAR_DIR/src/bin/tree-converter -input_format penn -output_format egret &lt; ckylark-parse.txt &gt; ckylark-forest.txt
$TRAVATAR_DIR/script/tree/replace-failed-parse.pl -format egret ckylark-forest.txt egret-forest.txt &gt; egret-forestfixed.txt
</pre>

<p>
When using forests in decoding, we must pass the option "<tt>-in_format egret</tt>" to Travatar.
When running <tt>mert-travatar.pl</tt>, this can be done using "<tt>-decoder-options '-in_format egret'</tt>".
</p>

<a name="japanese"/>
<h2>Parsing Japanese</h2>

<p>
Before parsing Japanese, it is necessary to tokenize the text.
This can be done using the <a href="http://www.phontron.com/kytea">KyTea</a> segmenter.
Install it according to the directions on the site, then tokenize using the following command (<tt>notags</tt> turns of POS tagging, and <tt>wsconst</tt> prevents dividing numbers): 
</p>

<pre>
kytea -notags -wsconst D &lt; input.txt &gt; tokenized.txt
</pre>

<p>
For parsing Japanese, it is possible to use Ckylark and Egret like for English.
The Japanese model in Ckylark is labeled <tt>jdc</tt>, and the Japanese model in Egret is labeled <tt>jpn_grammar</tt>.
</p>

<a name="chinese"/>
<h2>Parsing Chinese</h2>

<p>
Both the <a href="http://nlp.stanford.edu/software/lex-parser.shtml#Download">Stanford Parser</a> and <a href="http://code.google.com/p/egret-parser/">Egret</a> support parsing Chinese, and thus can be used in the same fashion as English.
</p>

<a name="defr"/>
<h2>Parsing German/French</h2>

<p>
The <a href="http://nlp.stanford.edu/software/lex-parser.shtml#Download">Stanford Parser</a> supports German and French, so it can be used to generate trees.
</p>

</div>
</div>

</body>
</html>
