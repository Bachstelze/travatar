<html>
<head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <title>Travatar - Parsing for Travatar</title>
    <link href="main.css" rel="stylesheet" type="text/css">
</head>
<body>

<div id="all">
<div id="sidebar">

<p>Travatar Main</p>
<ul>
<li><a href="index.html">Home</a></li>
<li><a href="todo.html">Future Plans</a></li>
</ul>

<p>Training</p>
<ul>
<li><a href="training-guide.html">Training Guide</a></li>
<li><a href="preprocessing.html">Preprocessing</a></li>
<li><a href="parsing.html">Parsing</a></li>
<li><a href="training-options.html">Training Options</a></li>
<li><a href="tree-converter.html">Tree Conversion</a></li>
<li><a href="model-format.html">Model Format</a></li>
</ul>

<p>Translating</p>

<ul>
<li><a href="decoding-options.html">Decoding Options</a></li>
<li><a href="evaluation.html">Evaluation</a></li>
</ul>

<p>Other</p>

<ul>
<li><a href="links.html">Links/ Acknowledgements</a></li>
</ul>


</div>
<div id="main">

<h1>Parsing for Travatar</h1>

<p>
Travatar is a tree-to-string translation system, which means that it requires source language parse trees to perform translation.
Within this framework, better parse trees will often directly improve your translation accuracy, so it is worth investing a little bit of time to created good trees.
It can also use packed forests, which encode a large number of trees at decoding time, so using a parser that has the ability to output packed forests is also effective.
This page describes how to perform the parsing step on your own, which is useful if you want to adjust various parameters of the parser, but there is also a <a href="preprocessing.html">preprocessing script</a> that makes it a bit easier to get going quickly.
</p>

<ul>
<li><a href="#english">Parsing English</a></li>
<li><a href="#japanese">Parsing Japanese</a></li>
<li><a href="#chinese">Parsing Chinese</a></li>
<li><a href="#defr">Parsing German/French</a></li>
</ul>

<a name="english">
<h2>Parsing English</h2>

<p>
For parsing English, you can use any phrase structure parser of your choosing.
In particular, we recommend the <a href="http://github.com/odashi/Ckylark">Ckylark</a> parser for trees, or <a href="http://github.com/neubig/egret">Egret</a> parser for forests.
Note that parsing has a large effect on translation results (<a href="http://phontron.com/paper/neubig14acl.pdf">Neubig&Duh ACL2014</a>), so it might be worth trying other newer parsers.
</p>

<h3>Tokenization</h3>

<p>
Before parsing, you will have to tokenize your input.
Travatar includes a tokenizer that does a reasonable job at tokenizing English, so you can use it on an input text <tt>input.txt</tt> as follows:
</p>

<pre>
cat input.txt | travatar/src/bin/tokenizer &gt; tokenized.txt
</pre>

<h3>Ckylark</h3>

<p>
As mentioned in the <a href="training-guide.html">training guide</a>, the <a href="http://github.com/odashi/Ckylark">Ckylark</a> parser is a good parser for generating trees, as it is accurate and will rarely fail at parsing.
To install the parser, if you haven't already, clone it from github, and follow the installation directions.
Then, if we want to parse English we will have to unzip the English parsing model (named WSJ, as it was trained on the Wall Street Journal section of the Penn Treebank).
</p>

<pre>
gunzip Ckylark/model/wsj.*.gz
</pre>

<p>
Next, we can use this model to parse English sentences using the following command.
</p>

<pre>
cat tokenized.txt | Ckylark/src/ckylark --model Ckylark/model/wsj &gt; ckylark-parsed.txt
</pre>

<h3>Egret</h3>

<p>
<a href="http://code.google.com/p/egret-parser/">Egret</a> is a parser that is able to output packed forests that can be used in translation.
</p>

<h4>Installation</h4>

<p>
Download Egret from the <a href="http://github.com/neubig/egret">github page</a> and unzip it.
You can then run the following command in the top directory to compile:
</p>
<pre>
bash make-linux.sh
</pre>

<h4>Parsing 1-best Trees</h4>

<p>
For Travatar training (currently) only 1-best trees are supported for rule learning, so we will first describe how to create 1-best trees.
Given the tokenized file <tt>tokenized.txt</tt>, we then run Egret as follows, where <tt>$EGRET_DIR</tt> is the directory to which you downloaded Egret.
</p>

<pre>
$EGRET_DIR/egret -lapcfg -i=tokenized.txt -data=$EGRET_DIR/eng_grammar &gt; egret-parsed.txt
</pre>

<p>
Unfortunately, for some sentences, Egret's parsing fails and generates an empty tree "(())", maybe one in every 10000 or so sentences.
This means that we will not be able to extract rules from, or translate any failed sentences.
If we already have parse trees from the Ckylark parser, we can use the script <tt>replace-failed-parse.pl</tt> included with Travatar to replace only failed parses.
</p>

<pre>
$TRAVATAR_DIR/script/tree/replace-failed-parse.pl ckylark-parsed.txt egret-parsed.txt &gt; egret-parsefixed.txt
</pre>

<p>
If parsing is taking a lot of time, you can parse in parallel by running Egret on multiple processors and specifying <tt>-range</tt> to indicate which sentences you want to parse in that particular instance.
For example, if you have 1000 sentences to parse, you could run the following
</p>

<pre>
$EGRET_DIR/egret -range=1-500 -lapcfg -i=tokenized.txt -data=$EGRET_DIR/eng_grammar &gt; egret-parsed-1.txt &amp;
$EGRET_DIR/egret -range=501-1000 -lapcfg -i=tokenized.txt -data=$EGRET_DIR/eng_grammar &gt; egret-parsed-2.txt &amp;
</pre>

<p>
and then combine the two files together when both processes finish running.
</p>

<h4>Parsing Forests</h4>

<p>
Creating forests with Egret just requires a few extra options.
An example of the command can be found below:
</p>

<pre>
$EGRET_DIR/egret -lapcfg -i=tokenized.txt -data=$EGRET_DIR/eng_grammar -nbest4threshold=100 -printForest &gt; egret-forest.txt
</pre>

<p>
Here <tt>nbest4threshold=100</tt> indicates that we will only keep nodes or edges that appear in the 100 best parse trees.
This is generally a good setting, but larger forests can sometimes improve accuracy (<a href="http://phontron.com/paper/neubig14acl.pdf">Neubig&Duh ACL2014</a>).
</p>

<p>
Again, as some parses may fail, you can replace them with parses from Ckylark.
In order to do so, we first convert the Ckylark trees to forests with the <tt>tree-converter</tt> tool provided with Travatar, and then use the <tt>replace-failed-parse.pl</tt> script as we did before.
</p>

<pre>
$TRAVATAR_DIR/src/bin/tree-converter -input_format penn -output_format egret &lt; ckylark-parse.txt &gt; ckylark-forest.txt
$TRAVATAR_DIR/script/tree/replace-failed-parse.pl -format egret ckylark-forest.txt egret-forest.txt &gt; egret-forestfixed.txt
</pre>

<p>
When using forests in decoding, we must pass the option "<tt>-in_format egret</tt>" to Travatar.
When running <tt>mert-travatar.pl</tt>, this can be done using "<tt>-decoder-options '-in_format egret'</tt>".
</p>

<a name="japanese"/>
<h2>Parsing Japanese</h2>

<p>
The following directions are for parsing Japanese.
In Japanese, dependency parsers are the most widely used method for parsing, so we first create a dependency parse, then use heuristic rules to convert this into the format used by Travatar.
We have found that the <a href="http://www.ar.media.kyoto-u.ac.jp/members/flannery/eda/index_en.html">Eda dependency parser</a> gives good results, so we will use it here.
</p>

<h3>Eda</h3>

<p>
To perform parsing with <a href="http://www.ar.media.kyoto-u.ac.jp/members/flannery/eda/index_en.html">Eda</a>, you will first have to install both Eda and <a href="http://www.phontron.com/kytea">KyTea</a>, a Japanese tokenizer and POS tagger.
</p>

<h4>Installation</h4>

<p>
Download each of the tools from the website.
Install KyTea using the following commands:
</p>

<pre>
tar -xzf kytea-X.X.X.tar.gz
cd kytea-X.X.X
./configure
make
sudo make install
</pre>

<p>
Next, build Eda:
</p>

<pre>
tar -xzf eda-X.X.X.tar.gz
cd eda
make
</pre>

<p>
And we will assume that <tt>$EDA_DIR</tt> is set to the directory that Eda is installed to.
</p>

<h4>Parsing</h4>

<p>
Parsing Japanese with Eda and turning it into a format usable by Travatar is a string of several commands, but can be done in a single step.
</p>

<pre>
cat input.txt |
    kytea -wsconst D -out eda | 
    $EDA_DIR/src/eda/eda \
      -v $EDA_DIR/data/jp-0.1.0-utf8-vocab-small.dat \
      -w $EDA_DIR/data/jp-0.1.0-utf8-weight-small.dat |
    $TRAVATAR_DIR/script/tree/ja-adjust-dep.pl |
    $TRAVATAR_DIR/script/tree/ja-dep2cfg.pl &gt;
        eda-parse.txt
</pre>

<p>
Describing each of these commands briefly, <tt>kytea</tt> performs word segmentation and POS tagging, <tt>treeify.py</tt> converts KyTea's output to a format that eda can read, and <tt>eda</tt> performs dependency parsing.
<tt>ja-adjust-dep.pl</tt> adjusts some peculiarities of Japanese dependency annotation (most notably making punctuation and auxiliary verbs children instead of heads), and <tt>ja-dep2cfg.pl</tt> converts dependency trees to CFG trees and performs binarization according to some linguistically motivated head rules.
The output of this sequence of commands should be sufficient for using as input to Travatar.
</p>

<a name="chinese"/>
<h2>Parsing Chinese</h2>

<p>
Both the <a href="http://nlp.stanford.edu/software/lex-parser.shtml#Download">Stanford Parser</a> and <a href="http://code.google.com/p/egret-parser/">Egret</a> support parsing Chinese, and thus can be used in the same fashion as English.
</p>

<a name="defr"/>
<h2>Parsing German/French</h2>

<p>
The <a href="http://nlp.stanford.edu/software/lex-parser.shtml#Download">Stanford Parser</a> supports German and French, so it can be used to generate trees.
</p>

</div>
</div>

</body>
</html>
